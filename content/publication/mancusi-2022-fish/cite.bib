@article{mancusi2022fish,
 abstract = {The marine ecosystem faces alarming changes, including biodiversity loss and the migration of tropical species to temperate regions. Monitoring underwater environments and their inhabitants is crucial, but challenging in vast and uncontrolled areas like oceans. Passive acoustics monitoring (PAM) has emerged as an effective method, using hydrophones to capture underwater sound. Soundscapes with rich sound spectra indicate high biodiversity, soniferous fish vocalizations can be detected to identify specific species. Our focus is on sound separation within underwater soundscapes, isolating fish vocalizations from background noise for accurate biodiversity assessment. To address the lack of suitable datasets, we collected fish vocalizations from online repositories and captured sea soundscapes at various locations. We propose an online generation of synthetic soundscapes to train two popular sound separation networks. Our study includes comprehensive evaluations on a synthetic test set, showing that these separation models can be effectively applied in our settings, yielding encouraging results. Qualitative results on real data showcase the model's generalization ability. Utilizing sound separation networks enables automatic extraction of fish vocalizations from PAM recordings, enhancing biodiversity monitoring and capturing animal sounds in their natural habitats.},
 author = {Mancusi, Michele and Zonca, Nicola and Rodol√†, Emanuele and Zuffi, Silvia},
 doi = {10.1109/I3DA57090.2023.10289193},
 journal = {2023 Immersive and 3D Audio: from Architecture to Automotive (I3DA)},
 title = {Towards the evaluation of marine acoustic biodiversity through data-driven audio source separation},
 url = {https://ieeexplore.ieee.org/abstract/document/10289193},
 year = {2023}
}

